{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Tensile Strength of Composite Materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11698246772327639041\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 20312045056\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 28533055535198546\n",
      "physical_device_desc: \"device: 0, name: DML, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15229974720\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 17732169278860695957\n",
      "physical_device_desc: \"device: 1, name: DML, pci bus id: <undefined>\"\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[0], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def test_op():\n",
    "    return tf.linalg.matmul(tf.random.normal((512, 512)), tf.random.normal((512, 512)))\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    result = test_op()\n",
    "    print(\"Ran on GPU:0\")\n",
    "    print(result)\n",
    "\n",
    "with tf.device('/GPU:1'):\n",
    "    result = test_op()\n",
    "    print(\"Ran on GPU:1\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The Composite Materials dataset hosted on Kaggle provides a comprehensive collection of data intended to aid in the modeling and prediction of mechanical properties of composite materials. This dataset is particularly relevant for materials scientists and engineers focused on understanding how different constituent components—such as fiber type, matrix material, volume fraction, and manufacturing parameters—affect key mechanical performance indicators like tensile strength and Young’s modulus. It facilitates machine learning and regression-based studies, enabling researchers to explore the relationship between material composition and resultant properties. The dataset serves as a valuable resource for educational projects, industrial material design, and predictive modeling in composite mechanics.\n",
    "    \n",
    "The dataset can be used to train machine learning models that Young’s modulus based on constituent properties and processing conditions—helping accelerate material discovery and design. In industrial applications, engineers can utilize the dataset to optimize composite formulations for lightweight structures in aerospace, automotive, and civil engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRISP-DM FRAMEWORK\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "To frame the task, throughout this project, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Here is a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Business Understanding\n",
    "\n",
    "**Objective:** Predict one of important mechanical properties, Young’s modulus of composite materials based on their composition and processing parameters.\n",
    "\n",
    "**Goals:**\n",
    "- Develop a predictive model to assist material design.\n",
    "- Identify which factors most strongly influence mechanical performance.\n",
    "- Support material selection for lightweight, high-strength applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input:\n",
    "\n",
    "- **Matrix-filler ratio:** The proportion of the polymer matrix to the filler material in the composite\n",
    "- **Density, kg/m3:** The mass per unit volume of the composite material.\n",
    "- **Modulus of elasticity, GPa:** Young’s modulus of the base material or resin, indicating its ability to resist elastic deformation.\n",
    "- **Amount of hardener, m.%:** Percentage of hardening agent (often a curing agent in thermosets) relative to the total mass.\n",
    "- **Content of epoxy groups, %:** The percentage of reactive epoxy functional groups in the resin formulation\n",
    "- **Flash point, C_2:** The lowest temperature at which the resin emits vapors that can ignite in air.\n",
    "- **Surface density, g/m2:** Mass of material (often fabric or prepreg) per unit surface area.\n",
    "- **Tensile modulus of elasticity, GPa:** The modulus specifically measured under tensile (pulling) stress.\n",
    "- **Resin consumption, g/m2:** The amount of resin required per unit area of reinforcement during composite fabrication.\n",
    "\n",
    "#### Output:\n",
    "- **Tensile strength, MPa:** Maximum stress the material can withstand under tension before failure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import category_encoders as ce\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data and Get General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_excel('./data/X_bp.xlsx');\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.rename(columns={\n",
    "    'Соотношение матрица-наполнитель': 'Matrix-filler ratio',\n",
    "    'Плотность, кг/м3': 'Density, kg/m³',\n",
    "    'модуль упругости, ГПа': 'Modulus of elasticity, GPa',\n",
    "    'Количество отвердителя, м.%': 'Amount of hardener, mass %',\n",
    "    'Содержание эпоксидных групп,%_2': 'Content of epoxy groups, %',\n",
    "    'Температура вспышки, С_2': 'Flash point, °C',\n",
    "    'Поверхностная плотность, г/м2': 'Surface density, g/m²',\n",
    "    'Модуль упругости при растяжении, ГПа': 'Tensile modulus of elasticity, GPa',\n",
    "    'Прочность при растяжении, МПа': 'Tensile strength, MPa',\n",
    "    'Потребление смолы, г/м2': 'Resin consumption, g/m²'\n",
    "})\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: \n",
    "- There are 9 columns, and 1023 entries. There is no missing value in dataset\n",
    "- Mostly numeric columns (float64 or int64), making the dataset suitable for regression and correlation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUMMARY\n",
    "\n",
    "**Matrix-filler ratio**\n",
    "- Mean: 2.93, indicating that on average, the matrix is almost three times more prevalent than the filler. Range: 0.39 to 5.59, showing diverse compositions across samples.\n",
    "- Insight: A higher matrix ratio may lead to lower stiffness but increased toughness.\n",
    "\n",
    "**Density (kg/m³)**:\n",
    "- Mean: 1975.73 kg/m³\n",
    "- Std Dev: 73.73 kg/m³ — moderate variability.\n",
    "- Range: 1731.76 to 2207.77 kg/m³\n",
    "- Insight: The dataset focuses on medium- to high-density composite materials, suitable for structural applications.\n",
    "\n",
    "**Modulus of Elasticity (GPa)**\n",
    "- Mean: 739.92 GPa — quite high, which may reflect the stiffness of constituent materials.\n",
    "- Range: 2.44 to 1911.54 GPa — wide variation depending on composite formulation.\n",
    "\n",
    "**Amount of Hardener (mass %)**\n",
    "- Mean: 110.57%. Range: 17.74% to 198.95%\n",
    "- Insight: Some formulations use significantly higher hardener content, which may influence curing rate and crosslink density.\n",
    "\n",
    "**Content of Epoxy Groups (%)**\n",
    "- Mean: ~22.24%\n",
    "- Insight: This controls the cross-linking potential and impacts mechanical and thermal performance.\n",
    "\n",
    "**Flash Point (°C)**\n",
    "- Mean: 285.88°C\n",
    "- Range: 100°C to 364.61°C\n",
    "- Insight: Higher flash points imply safer processing and higher thermal stability.\n",
    "\n",
    "**Surface Density (g/m²)**\n",
    "- Mean: 482.73 g/m². Std Dev: 281.31 — high variation.\n",
    "- Insight: Indicates varied prepreg or fiber areal weights, which affect final part thickness and performance.\n",
    "\n",
    "**Tensile Modulus of Elasticity (GPa)**\n",
    "- Mean: 73.33 GPa. Range: 64.05 to 81.44 GPa\n",
    "- Insight: Moderate variation suggests consistent tensile stiffness across samples.\n",
    "\n",
    "**Tensile Strength (MPa)**\n",
    "- Mean: 2466.92 MPa\n",
    "- Range: 1036.86 to 3630.35 MPa\n",
    "- Insight: High strength levels, consistent with advanced structural composites.\n",
    "\n",
    "**Resin Consumption (g/m²)**\n",
    "- Mean: 218.42 g/m²\n",
    "- Range: 33.80 to 382.49 g/m²\n",
    "- Insight: Wide variability may be related to fiber architecture and manufacturing process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Heatmap of Numerical Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation of all features with Tensile strength\n",
    "corr_with_target = df.corr(numeric_only=True)['Tensile strength, MPa'].drop('Tensile strength, MPa')\n",
    "\n",
    "# Sort by absolute correlation value for better insight\n",
    "corr_sorted = corr_with_target.abs().sort_values(ascending=False).to_frame(name='Correlation with Tensile Strength')\n",
    "corr_sorted['Signed Correlation'] = corr_with_target[corr_sorted.index]\n",
    "corr_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: The correlation analysis reveals that tensile strength has very weak linear relationships with all other numerical input features in the dataset.\n",
    "\n",
    "**Positive Correlations:**\n",
    "- Modulus of Elasticity (GPa): +0.042. Suggests a very slight trend that stiffer materials may have slightly higher tensile strength, though this is statistically negligible.\n",
    "\n",
    "**Negative Correlations:**\n",
    "- Amount of Hardener (mass %): –0.075\n",
    "- Density (kg/m³): –0.070\n",
    "- Flash Point (°C): –0.032\n",
    "- These show slight negative trends, implying that as these values increase, tensile strength may decrease marginally. However, these values are far too low to suggest a meaningful or actionable relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Histogram for each numeric feature\n",
    "df.hist(figsize=(15, 12), bins=20, edgecolor='black')\n",
    "plt.suptitle(\"Histograms of Numeric Features\", fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pair plot (subset to avoid overcrowding)\n",
    "sns.pairplot(df[['Tensile strength, MPa','Amount of hardener, mass %','Density, kg/m³',\n",
    "                'Modulus of elasticity, GPa', 'Flash point, °C', 'Resin consumption, g/m²']])\n",
    "plt.suptitle(\"Pair Plot of Key Features\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms** showing the distribution of each numeric feature. Most features show moderately normal or skewed distributions, with Tensile Strength and Resin Consumption having wide spreads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "- To find meaningful ratios among the factors influencing tensile strength in composites, we focus on combining features that relate to reinforcement content, matrix effectiveness, and mechanical performance. Ratios can help normalize effects or reveal proportional trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Matrix Efficiency Ratio:** Tensile strength / Matrix-filler ratio\n",
    "- Interpretation: Strength achieved per unit matrix content.\n",
    "- A higher value suggests the matrix is effectively transferring load to the filler.\n",
    "\n",
    "2. **Specific Tensile Strength:** Tensile strength / Density\n",
    "- Interpretation: Measures how strong the composite is per unit weight.\n",
    "- Used widely in aerospace and automotive industries for lightweight design.\n",
    "\n",
    "3. **Modulus-to-Strength Ratio:** Modulus of elasticity / Tensile strength\n",
    "- Interpretation: Indicates brittleness.\n",
    "- A higher value implies stiffer but potentially more brittle material.\n",
    "\n",
    "4. **Fiber Efficiency Ratio:** Tensile strength / Resin consumption\n",
    "- Interpretation: Evaluates how efficiently the composite converts resin mass into tensile strength.\n",
    "- Useful for optimizing resin usage vs strength.\n",
    "\n",
    "5. **Crosslinking Efficiency:** Tensile strength / Amount of hardener\n",
    "- Interpretation: Higher values could indicate more efficient curing and stronger fiber-matrix interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Matrix Efficiency Ratio\"] = df[\"Tensile strength, MPa\"] / df['Matrix-filler ratio']\n",
    "df[\"Specific Tensile Strength\"] = df[\"Tensile strength, MPa\"] / df[\"Density, kg/m³\"]\n",
    "df[\"Modulus-to-Strength\"] = df['Tensile modulus of elasticity, GPa'] / df['Tensile strength, MPa']\n",
    "df[\"Fiber Efficiency Ratio\"] = df[\"Tensile strength, MPa\"] / df['Resin consumption, g/m²']\n",
    "df[\"Crosslinking Efficiency\"] = df[\"Tensile strength, MPa\"] / df['Amount of hardener, mass %']\n",
    "df[\"Stiffness-to-Fiber-Loading\"] = df['Tensile modulus of elasticity, GPa'] / df['Matrix-filler ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True)\n",
    "plt.title(\"Correlation Heatmap of Numerical Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation of all features with Tensile strength\n",
    "corr_with_target = df.corr(numeric_only=True)['Tensile strength, MPa'].drop('Tensile strength, MPa')\n",
    "\n",
    "# Sort by absolute correlation value for better insight\n",
    "corr_sorted = corr_with_target.abs().sort_values(ascending=False).to_frame(name='Correlation with Tensile Strength')\n",
    "corr_sorted['Signed Correlation'] = corr_with_target[corr_sorted.index]\n",
    "corr_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pair plot (subset to avoid overcrowding)\n",
    "sns.pairplot(df[['Tensile strength, MPa','Specific Tensile Strength','Modulus-to-Strength', \n",
    "                 'Crosslinking Efficiency', 'Fiber Efficiency Ratio','Matrix Efficiency Ratio']])\n",
    "plt.suptitle(\"Pair Plot of Key Features\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Tensile strength, MPa', axis=1)\n",
    "y = df['Tensile strength, MPa']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42);\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Base Model with Default Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('linreg', LinearRegression())]);\n",
    "basemodel.fit(X_train, y_train);\n",
    "basemodel.score(X_test, y_test);\n",
    "\n",
    "base_y_testPred = basemodel.predict(X_test);\n",
    "\n",
    "base_mse = mean_squared_error(y_test, base_y_testPred);\n",
    "base_score = basemodel.score(X_test,y_test);\n",
    "print(f\"Mean Squared Error of the base model: {base_mse}\")\n",
    "print(f\"Score of the base model: {base_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - Apply Polynomial Feature to find optimal degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mses = []\n",
    "test_mses = []\n",
    "test_score = []\n",
    "for i in range(1,5):\n",
    "    pipe = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=i, include_bias=False)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train);\n",
    "    train_preds = pipe.predict(X_train);\n",
    "    test_preds = pipe.predict(X_test);\n",
    "    train_mses.append(mean_squared_error(y_train, train_preds));\n",
    "    test_mses.append(mean_squared_error(y_test, test_preds));\n",
    "    test_score.append(pipe.score(X_test,y_test));\n",
    "\n",
    "best_model_complexity = test_mses.index(min(test_mses)) + 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The Complexity that minimized Test Error was: {test_mses.index(min(test_mses)) + 1}')\n",
    "print(f'The Best MSE of Test Error was: {min(test_mses)}')\n",
    "print(f'The Best Score of Test Set was: {max(test_score)}')\n",
    "plt.plot(range(1,5), train_mses, '--o', label = 'training error')\n",
    "plt.plot(range(1,5), test_mses, '--o', label = 'testing error')\n",
    "plt.xticks(range(1, 5), range(1, 5))\n",
    "plt.xlabel('Degree Complexity')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 - Ridge Regresion Model with GridSearch to find optimal alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'ridge__alpha': [0.0001, 0.001, 0.1, 1.0, 10.0, 100.0, 1000]}\n",
    "\n",
    "ridgemodel = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "]);\n",
    "\n",
    "# Create the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=ridgemodel, param_grid=param_dict, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha value found by GridSearchCV\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "print(f\"Best alpha value: {best_alpha}\")\n",
    "\n",
    "# Get the best model (Lasso with the best alpha)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "ridge_mse = mean_squared_error(y_test, y_pred)\n",
    "ridge_score = best_model.score(X_test,y_test);\n",
    "print(f\"Mean Squared Error of the best model: {ridge_mse}\")\n",
    "print(f\"Score of the best model: {ridge_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 - Random Forest Model + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'rf__n_estimators': np.arange(50,300,50)}\n",
    "\n",
    "rf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(random_state=42))\n",
    "]);\n",
    "\n",
    "# Create the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_dict, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha value found by GridSearchCV\n",
    "best_n = grid_search.best_params_['rf__n_estimators']\n",
    "print(f\"Best n_estimator value: {best_n}\")\n",
    "\n",
    "# Get the best model (Lasso with the best alpha)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_mse = mean_squared_error(y_test, y_pred)\n",
    "rf_score = best_model.score(X_test,y_test);\n",
    "print(f\"Mean Squared Error of the best model: {rf_mse}\")\n",
    "print(f\"Score of the best model: {rf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Gradient Boosting Model + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'gb__n_estimators': np.arange(50,300,50)}\n",
    "\n",
    "gb = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('gb', GradientBoostingRegressor(random_state=42))\n",
    "]);\n",
    "\n",
    "# Create the GridSearchCV object with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=gb, param_grid=param_dict, cv=5, scoring='r2')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha value found by GridSearchCV\n",
    "best_n = grid_search.best_params_['gb__n_estimators']\n",
    "print(f\"Best n_estimator value: {best_n}\")\n",
    "\n",
    "# Get the best model (Lasso with the best alpha)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "gb_mse = mean_squared_error(y_test, y_pred)\n",
    "gb_score = best_model.score(X_test,y_test);\n",
    "print(f\"Mean Squared Error of the best model: {gb_mse}\")\n",
    "print(f\"Score of the best model: {gb_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {'ridge__alpha': [0.0001, 0.001, 0.1, 1.0, 10.0, 100.0, 1000]}\n",
    "\n",
    "finalmodel = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('ridge', Ridge())\n",
    "]);\n",
    "\n",
    "# Create the GridSearchCV object with 5-fold cross-validation\n",
    "grid = GridSearchCV(estimator=finalmodel, param_grid=param_dict, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best alpha value found by GridSearchCV\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "print(f\"Best alpha value: {best_alpha}\")\n",
    "\n",
    "# Get the best model\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "finalmodel_mse = mean_squared_error(y_test, y_pred)\n",
    "finalmodel_score = best_model.score(X_test,y_test);\n",
    "print(f\"Mean Squared Error of the final model: {finalmodel_mse}\")\n",
    "print(f\"Score of the final model: {finalmodel_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate the important of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the permutation importance of Test Set\n",
    "results = permutation_importance(final_model, X_test, y_test);\n",
    "results = pd.DataFrame(data=results.importances_mean.round(4), index=X.columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the permutation importance\n",
    "results = permutation_importance(final_model, X_train, y_train);\n",
    "results = pd.DataFrame(data=results.importances_mean.round(4), index=X.columns, columns=['Importance']).sort_values(by='Importance', ascending=False)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Further Studying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-directml",
   "language": "python",
   "name": "tf-directml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
